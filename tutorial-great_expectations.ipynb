{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectations tutorial\n",
    "Welcome! In this tutorial we'll have a look at Great Expectations, a python library that aids you in keeping an eye on your data quality. It provides a batteries-included solution for testing and documenting your data, so that nobody has to run into any surprises when consuming it. To achieve this, you create _expectation suites_. You can think of them like unit tests, but for data. They also double as documentation for your dataset, so that you won't have to repeat yourself.\n",
    "\n",
    "### What is Great Expectations exactly?\n",
    "\n",
    "![in_out](figures/in_out.png)\n",
    "\n",
    "Great Expectations can be used with your existing data assets - it is able to run on different backends such as SQL databases, Spark clusters, or just your plain old filesystem. It will execute your expectation suites on these backends, and generate reports on the results of your validation. \\\n",
    "Writing your expectation suite is usually done through jupyter notebooks, so you'll feel at home. This notebook itself would be an example of how that works!\n",
    "\n",
    "\n",
    "### In this tutorial\n",
    "We'll give you a brief introduction to the main concepts used in Great Expectations, walking you through writing your first expectations and generating your first data report. We have added many references to the official documentation that you can reference to when you are configuring your own setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into it then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need a `DataContext`. This represents a Great Expectations project, holding all your configurations, expectation suites, data sources and so on. We'll have a better look at the data context later [[jump ahead]](#section-data-context), but just to get started we shipped a simple one with this tutorial.\n",
    "\n",
    "We'll load that one right now. By default, Great Expectations will look for your configuration in the `great_expectations` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `DataContext` ready, we can add an expectation suite. Think of this like a test suite, but for your data instead of for your code. Usually you'll do this through the CLI, but we will get to that later [[jump ahead]](#section-cli). We'll name the suite `check_avocado_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = context.create_expectation_suite(\n",
    "    \"check_avocado_data\",\n",
    "    overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our dataset, `avocado.csv`, from our data context. This involves a bit of configuration, but don't worry about it too much for now. We'll get back to that later [TODO: when + link]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kwargs = {\n",
    "      'path': 'data/avocado.csv',\n",
    "      'datasource': 'data_dir',\n",
    "      'reader_method': 'read_csv',\n",
    "      'data_asset_name': 'avocado',\n",
    "}\n",
    "batch = context.get_batch(batch_kwargs, suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that's it for setup!\n",
    "\n",
    "Let's continue to our avocado sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "\n",
       "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "\n",
       "   year  region  \n",
       "0  2015  Albany  \n",
       "1  2015  Albany  \n",
       "2  2015  Albany  \n",
       "3  2015  Albany  \n",
       "4  2015  Albany  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the documentation that came with the data:\n",
    " - Date - The date of the observation\n",
    " - AveragePrice - the average price of a single avocado\n",
    " - type - agriculture type: conventional or organic\n",
    " - Region - the city or region of the observation\n",
    " - Total Volume - Total number of avocados sold\n",
    " - 4046 - Total number of avocados with PLU 4046 sold (small Hass)\n",
    " - 4225 - Total number of avocados with PLU 4225 sold (large Hass)\n",
    " - 4770 - Total number of avocados with PLU 4770 sold (extra large Hass)\n",
    " \n",
    "These descriptions sure help us to understand the dataset a bit better, but they don't exactly provide much guarantees. When consuming this dataset, what assumptions can we make? Will the `region` field always be specified? Will the `Date` field always be in the same format? Those sales counts, are they supposed to add up?\n",
    "\n",
    "Great Expectations helps us to codify these properties in a set of `Expectations`. An `Expectation` is, well, something that you expect to be true in your data. Again, think of it like an unit test for your dataset.\n",
    "\n",
    "Let's run a basic `Expectation` to get started. For example, we could check whether the `Date` column is present in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {},\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_to_exist('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `dict` we got back might feel a bit weird at first, but you'll see later on how this output is used to generate reports [[jump ahead]](#section-data-docs). For now, just note that `success` has the value `true`, indicating that our expectation passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple check that only assesses the data shape, but doesn't touch the values in there (it is a _table-level check_).\n",
    "\n",
    "Let's try adding a check for the values now. Maybe we can address one of the concerns we raised: can we add an `Expectation` that ensures every record will have its `region` specified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_not_be_null('region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! This time we got a bit more info back: the `result` section now contains some metrics about our data. We can see that all 18249 records passed the check, and there were no unexpected (i.e. `null`) values. If Great Expectations finds any offending values, they will be listed in the `partial_unexpected_list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do something that's a bit more strict. It would be nice, for example, to make sure that all `region`s are actually strings, so that we don't end up with numeric regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_of_type('region', 'str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that metrics on the amount of missing values were still collected. This way, we can disambiguate between missing values and incorrect values. In case you were wondering, the `unexpected_percent_nonmissing` refers to the percentage of present (non-null) values that did not meet our expectation (they were not a string). If other metrics are unclear to you, check out [this documentation page](https://docs.greatexpectations.io/en/latest/reference/core_concepts/expectations/result_format.html#behavior-for-summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we covered the basics, let's get to some fancier expectations. For example, we could make sure that all `Date`s are in the expected format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_match_strftime_format('Date', \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example: we can make sure all the listed avocado prices are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 11,\n",
       "    \"unexpected_percent\": 0.06027727546714888,\n",
       "    \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "    \"partial_unexpected_list\": [\n",
       "      0.49,\n",
       "      0.46,\n",
       "      3.03,\n",
       "      3.12,\n",
       "      3.25,\n",
       "      0.44,\n",
       "      0.49,\n",
       "      0.48,\n",
       "      3.05,\n",
       "      3.04,\n",
       "      3.17\n",
       "    ]\n",
       "  },\n",
       "  \"success\": false,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! That failed. Looks like we have some outliers here! Great Expectations helpfully collected them for us. By default, it will collect up to 20 examples of values that didn't meet the expectation (that's why it's called the _partial_ unexpected list).\n",
    "\n",
    "If we want to allow these outliers, we can add some tolerance to the check by using the `mostly` parameter. Let's settle for having 99% of avocados being priced within the range we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 11,\n",
       "    \"unexpected_percent\": 0.06027727546714888,\n",
       "    \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "    \"partial_unexpected_list\": [\n",
       "      0.49,\n",
       "      0.46,\n",
       "      3.03,\n",
       "      3.12,\n",
       "      3.25,\n",
       "      0.44,\n",
       "      0.49,\n",
       "      0.48,\n",
       "      3.05,\n",
       "      3.04,\n",
       "      3.17\n",
       "    ]\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0, mostly=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common usecase would be when you only expect a certain set of values to show up in a column. This is the case for our `type` column, since we only know about `conventional` and `organic` grown avocados. Let's add a check for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"observed_value\": [\n",
       "      \"conventional\",\n",
       "      \"organic\"\n",
       "    ],\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_distinct_values_to_be_in_set('type', ['conventional', 'organic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even add a check on the value frequencies! For example, if we want the ratio of organic to conventional to be roughly equal, we could check the [Kullback-Leiber divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between our assumed distribution, and the one that is observed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"observed_value\": 1.351245850704074e-08,\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_object = {\n",
    "    'values': ['conventional', 'organic'],\n",
    "    'weights': [0.5, 0.5],\n",
    "    \n",
    "}\n",
    "batch.expect_column_kl_divergence_to_be_less_than('type', partition_object, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we checked out some expectations, maybe try adding one yourself? You can check out the [glossary of expectations](https://docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html) for a complete list of what you can do. Go wild!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stage is all yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Expectation Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while we were experimenting up there, great_expectations remembered all the expectations we ran. We can now retrieve the suite contents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"data_asset_type\": \"Dataset\",\n",
       "  \"expectations\": [\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Date\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_to_exist\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"region\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"region\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Date\",\n",
       "        \"strftime_format\": \"%Y-%m-%d\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_match_strftime_format\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"AveragePrice\",\n",
       "        \"min_value\": 0.5,\n",
       "        \"max_value\": 3.0,\n",
       "        \"mostly\": 0.99\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"type\",\n",
       "        \"value_set\": [\n",
       "          \"conventional\",\n",
       "          \"organic\"\n",
       "        ]\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"type\",\n",
       "        \"partition_object\": {\n",
       "          \"values\": [\n",
       "            \"conventional\",\n",
       "            \"organic\"\n",
       "          ],\n",
       "          \"weights\": [\n",
       "            0.5,\n",
       "            0.5\n",
       "          ]\n",
       "        },\n",
       "        \"threshold\": 0.1\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_kl_divergence_to_be_less_than\",\n",
       "      \"meta\": {}\n",
       "    }\n",
       "  ],\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.13.4\"\n",
       "  },\n",
       "  \"expectation_suite_name\": \"check_avocado_data\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gave us the `dict` representation Great Expectations uses under the hood to keep track of our exepectation suite. Can you recognise some of the expectations we wrote?\n",
    "\n",
    "This representation can then be saved to a file, so that we can load it again at another time, without depending on the python code that produced it.\n",
    "\n",
    "Note that by default, expectations that failed on the `batch` we ran them against will be omitted. If you want to include them anyways, you could add the `discard_failed_expectations=False` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us get back to that configuration we mentioned earlier. As we said, it's just some files living in the `great_expectations` directory. This is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mgreat_expectations\u001b[0m\r\n",
      "├── \u001b[01;34mcheckpoints\u001b[0m\r\n",
      "├── \u001b[01;34mexpectations\u001b[0m\r\n",
      "│   └── check_avocado_data.json\r\n",
      "├── great_expectations.yml\r\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\r\n",
      "│   ├── \u001b[01;34mpandas\u001b[0m\r\n",
      "│   │   └── validation_playground.ipynb\r\n",
      "│   ├── \u001b[01;34mspark\u001b[0m\r\n",
      "│   │   └── validation_playground.ipynb\r\n",
      "│   └── \u001b[01;34msql\u001b[0m\r\n",
      "│       └── validation_playground.ipynb\r\n",
      "└── \u001b[01;34mplugins\u001b[0m\r\n",
      "    └── \u001b[01;34mcustom_data_docs\u001b[0m\r\n",
      "        ├── \u001b[01;34mrenderers\u001b[0m\r\n",
      "        ├── \u001b[01;34mstyles\u001b[0m\r\n",
      "        │   └── data_docs_custom_styles.css\r\n",
      "        └── \u001b[01;34mviews\u001b[0m\r\n",
      "\r\n",
      "11 directories, 6 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree great_expectations -I \"uncommitted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have the main `great_expectations.yml` configuration file, a folder with checkpoints, a folder with expectation suites, some playground notebooks, and a folder for plugins. \\\n",
    "[TODO: would it be better to move this part on the configuration folder to the next section?]\n",
    "\n",
    "As you can see, the `save_expectation_suite` command saved our `check_avocado_data` suite to the `expectations` folder! That's all there is to it, the expectation suite is just a file. It contains that same internal representation that we just retrieved. You can check if you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat great_expectations/expectations/check_avocado_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validation-results\"></a>\n",
    "Now that we added our expectation suite to our `DataContext`, we can try running the entire suite. This is done by applying a `ValidationOperator` to the suite and the dataset. `ValidationOperator`s for your project are defined in the `great_expectations.yml` file. We already provided a `ValidationOperator` called `action_list_operator` [TODO: would it be clearer to change this name to something more clear (it is the default name)?] which will run the expectation suite and record its results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = context.run_validation_operator(\"action_list_operator\", assets_to_validate=[batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't specify our expectation suite for that command, but remember that the `batch` dataset kept track of our suite for us, so it will know what to do.\n",
    "\n",
    "That produced a big datadump for us. Let's inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"run_id\": {\n",
       "    \"run_name\": \"20210119T111409.811156Z\",\n",
       "    \"run_time\": \"2021-01-19T11:14:09.811156+00:00\"\n",
       "  },\n",
       "  \"run_results\": {\n",
       "    \"ValidationResultIdentifier::check_avocado_data/20210119T111409.811156Z/20210119T111409.811156Z/a52e8a35d5f03815b708c7306612dbde\": {\n",
       "      \"validation_result\": {\n",
       "        \"results\": [\n",
       "          {\n",
       "            \"result\": {},\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"Date\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_to_exist\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"success\": true,\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"unexpected_percent_nonmissing\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"partial_unexpected_index_list\": [],\n",
       "              \"partial_unexpected_counts\": []\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"Date\",\n",
       "                \"strftime_format\": \"%Y-%m-%d\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_match_strftime_format\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"success\": true,\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"partial_unexpected_list\": []\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"region\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"success\": true,\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"unexpected_percent_nonmissing\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"partial_unexpected_index_list\": [],\n",
       "              \"partial_unexpected_counts\": []\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"region\",\n",
       "                \"type_\": \"str\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"success\": true,\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 11,\n",
       "              \"unexpected_percent\": 0.06027727546714888,\n",
       "              \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "              \"partial_unexpected_list\": [\n",
       "                0.49,\n",
       "                0.46,\n",
       "                3.03,\n",
       "                3.12,\n",
       "                3.25,\n",
       "                0.44,\n",
       "                0.49,\n",
       "                0.48,\n",
       "                3.05,\n",
       "                3.04,\n",
       "                3.17\n",
       "              ],\n",
       "              \"partial_unexpected_index_list\": [\n",
       "                1716,\n",
       "                7412,\n",
       "                13037,\n",
       "                14124,\n",
       "                14125,\n",
       "                15261,\n",
       "                15262,\n",
       "                15473,\n",
       "                16055,\n",
       "                16720,\n",
       "                17428\n",
       "              ],\n",
       "              \"partial_unexpected_counts\": [\n",
       "                {\n",
       "                  \"value\": 0.49,\n",
       "                  \"count\": 2\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.44,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.46,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.48,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.03,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.04,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.05,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.12,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.17,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.25,\n",
       "                  \"count\": 1\n",
       "                }\n",
       "              ]\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"AveragePrice\",\n",
       "                \"min_value\": 0.5,\n",
       "                \"max_value\": 3.0,\n",
       "                \"mostly\": 0.99,\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"success\": true,\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"observed_value\": [\n",
       "                \"conventional\",\n",
       "                \"organic\"\n",
       "              ],\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": null,\n",
       "              \"missing_percent\": null,\n",
       "              \"details\": {\n",
       "                \"value_counts\": [\n",
       "                  {\n",
       "                    \"value\": \"conventional\",\n",
       "                    \"count\": 9126\n",
       "                  },\n",
       "                  {\n",
       "                    \"value\": \"organic\",\n",
       "                    \"count\": 9123\n",
       "                  }\n",
       "                ]\n",
       "              }\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"type\",\n",
       "                \"value_set\": [\n",
       "                  \"conventional\",\n",
       "                  \"organic\"\n",
       "                ],\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"success\": true,\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"observed_value\": 1.351245850704074e-08,\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": null,\n",
       "              \"missing_percent\": null,\n",
       "              \"details\": {\n",
       "                \"observed_partition\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5000821962847279,\n",
       "                    0.49991780371527206\n",
       "                  ]\n",
       "                },\n",
       "                \"expected_partition\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5,\n",
       "                    0.5\n",
       "                  ]\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"type\",\n",
       "                \"partition_object\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5,\n",
       "                    0.5\n",
       "                  ]\n",
       "                },\n",
       "                \"threshold\": 0.1,\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              },\n",
       "              \"expectation_type\": \"expect_column_kl_divergence_to_be_less_than\",\n",
       "              \"meta\": {}\n",
       "            },\n",
       "            \"success\": true,\n",
       "            \"meta\": {},\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            }\n",
       "          }\n",
       "        ],\n",
       "        \"evaluation_parameters\": {},\n",
       "        \"success\": true,\n",
       "        \"meta\": {\n",
       "          \"great_expectations_version\": \"0.13.4\",\n",
       "          \"expectation_suite_name\": \"check_avocado_data\",\n",
       "          \"run_id\": {\n",
       "            \"run_name\": \"20210119T111409.811156Z\",\n",
       "            \"run_time\": \"2021-01-19T11:14:09.811156+00:00\"\n",
       "          },\n",
       "          \"batch_kwargs\": {\n",
       "            \"path\": \"data/avocado.csv\",\n",
       "            \"datasource\": \"data_dir\",\n",
       "            \"reader_method\": \"read_csv\",\n",
       "            \"data_asset_name\": \"avocado\"\n",
       "          },\n",
       "          \"batch_markers\": {\n",
       "            \"ge_load_time\": \"20210119T111153.925233Z\",\n",
       "            \"pandas_data_fingerprint\": \"9bc954aa566eaa4274cb680b2006c672\"\n",
       "          },\n",
       "          \"batch_parameters\": null,\n",
       "          \"validation_time\": \"20210119T111409.811937Z\"\n",
       "        },\n",
       "        \"statistics\": {\n",
       "          \"evaluated_expectations\": 7,\n",
       "          \"successful_expectations\": 7,\n",
       "          \"unsuccessful_expectations\": 0,\n",
       "          \"success_percent\": 100.0\n",
       "        }\n",
       "      },\n",
       "      \"actions_results\": {\n",
       "        \"store_validation_result\": {\n",
       "          \"class\": \"StoreValidationResultAction\"\n",
       "        },\n",
       "        \"store_evaluation_params\": {\n",
       "          \"class\": \"StoreEvaluationParametersAction\"\n",
       "        },\n",
       "        \"update_data_docs\": {\n",
       "          \"local_site\": \"file:///home/ilion/src/tutorial-great_expectations/great_expectations/uncommitted/data_docs/local_site/validations/check_avocado_data/20210119T111409.811156Z/20210119T111409.811156Z/a52e8a35d5f03815b708c7306612dbde.html\",\n",
       "          \"class\": \"UpdateDataDocsAction\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"evaluation_parameters\": null,\n",
       "  \"success\": true,\n",
       "  \"validation_operator_config\": {\n",
       "    \"class_name\": \"ActionListValidationOperator\",\n",
       "    \"module_name\": \"great_expectations.validation_operators\",\n",
       "    \"name\": \"action_list_operator\",\n",
       "    \"kwargs\": {\n",
       "      \"action_list\": [\n",
       "        {\n",
       "          \"name\": \"store_validation_result\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"StoreValidationResultAction\"\n",
       "          }\n",
       "        },\n",
       "        {\n",
       "          \"name\": \"store_evaluation_params\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"StoreEvaluationParametersAction\"\n",
       "          }\n",
       "        },\n",
       "        {\n",
       "          \"name\": \"update_data_docs\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"UpdateDataDocsAction\"\n",
       "          }\n",
       "        }\n",
       "      ],\n",
       "      \"result_format\": {\n",
       "        \"result_format\": \"SUMMARY\",\n",
       "        \"partial_unexpected_count\": 20\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a *validation result*. Validation results are kept in the *validation store*, which by default is the `great_expectations/uncommitted/validations` directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mgreat_expectations/uncommitted/validations\u001b[0m\r\n",
      "└── \u001b[01;34mcheck_avocado_data\u001b[0m\r\n",
      "    └── \u001b[01;34m20210119T111409.811156Z\u001b[0m\r\n",
      "        └── \u001b[01;34m20210119T111409.811156Z\u001b[0m\r\n",
      "            └── a52e8a35d5f03815b708c7306612dbde.json\r\n",
      "\r\n",
      "3 directories, 1 file\r\n"
     ]
    }
   ],
   "source": [
    "!tree great_expectations/uncommitted/validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great Expectations also allows you to set other backends as a validation store, such as an S3 bucket or a SQL database. Check out [metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) if you would like to learn more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-data-docs\"></a>\n",
    "## Data Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can render these results to a friendly report, called a data doc. These data docs will describe the expectations that the data should meet, as well as the metrics detailing how well the data meets the requirements. This is how Great Expectations combines testing with documenting. Running the code below will generate the data docs and open them in a new tab, make sure to have a look around. You'll see the code we ran above reflected in the different sections - it's pretty self-explanatory!\n",
    "\n",
    "TODO: make sure these docs are in the repo, and add a link to them for online readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.build_data_docs()\n",
    "\n",
    "# get the result identifier for our run\n",
    "validation_result_identifier = list(results[\"run_results\"].keys())[0]\n",
    "context.open_data_docs(validation_result_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we exracted that `validation_result_identifier` so we could bring you directly to the data doc for this validation result. When you're out there, you could just as well open the index and navigate to the result yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for validation results, different storage backends can be configured for your data docs. You could, for example, host them on an S3 bucket for easy viewing. Refer to [configuring data docs](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_data_docs.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-data-context\"></a>\n",
    "# Data Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's take a moment to look at the `DataContext`, which represents your Great Expectations setup. As we saw in the previous section, it consists of a directory with a `great_expectations.yml` file, which is the main configuration for your project. We won't focus on all the details here, you can refer to the [data context reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/data_context_reference.html) for that. Instead, we'll highlight some important concepts:\n",
    "\n",
    "- A **data source** is something that can provide data to Great Expectations, such as an SQL database.\n",
    "- A **data asset** is one dataset that lives in a *data source*, such as an SQL table.\n",
    "\n",
    "In the configuration we provided, there is one *data source* named `data_dir`, which is just a folder with csv files inside. the `avocado.csv` file we are working with would be a *data asset*.\n",
    "More information on data sources can be found in the [data context reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/data_context_reference.html#datasources).\n",
    "\n",
    "- A **validation operator** specifies what should be done with your validations. Some examples could be writing the validation results to a database, publishing data docs, or sending a notification to a slack channel.\n",
    "    If you'd like to know more you can check out the [validation operators and actions](https://docs.greatexpectations.io/en/latest/reference/core_concepts/validation_operators_and_actions.html) and [how to add a validation operator](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/validation/how_to_add_a_validation_operator.html) documentation pages.\n",
    "\n",
    "\n",
    "- **stores** specify where expectation and validation data will be stored. See [configuring metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) if you're interested.\n",
    "\n",
    "These are all configured in the `great_expectations.yml` file.\n",
    "\n",
    "In addition to those, we still have two important directories:`expectations`, which holds our expectation suites, and `checkpoints`, which we'll check out now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we manually ran our expectation suite against our dataset. While that worked, there is a better way: checkpoints.\n",
    "\n",
    "A checkpoint has three components:\n",
    "- A *data asset* that will be validated\n",
    "- *Expectation suites* to validate the data\n",
    "- A *validation operator* to handle the validation\n",
    "\n",
    "We can create a checkpoint by adding a file in the `checkpoints` directory of our great_expectations configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing great_expectations/checkpoints/avocado_data.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile great_expectations/checkpoints/avocado_data.yml\n",
    "\n",
    "validation_operator_name: action_list_operator\n",
    "batches:\n",
    "  - batch_kwargs:\n",
    "      path: data/avocado.csv\n",
    "      datasource: data_dir\n",
    "      reader_method: read_csv\n",
    "      data_asset_name: avocado\n",
    "    expectation_suite_names:\n",
    "      - check_avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`batches` is a list of (data batch, expectation suites) pairs. `batch_kwargs` specifies how the data asset should be loaded, you might recognise the parameters from earlier!\n",
    "\n",
    "We created the file manually here for demonstration purposes, but when doing this in your own project you probably want to use the CLI [[jump ahead]](#section-cli), which will also help you in setting the right parameters. If you need to configure them further, try [creating batches](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/creating_batches.html).\n",
    "\n",
    "The checkpoint can be executed by using the great_expectations cli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mHeads up! This feature is Experimental. It may change. Please give us your feedback!\u001b[0m\u001b[0m\n",
      "Validation succeeded!\u001b[0m\n",
      "\n",
      "Suite Name                                   Status     Expectations met\u001b[0m\n",
      "- check_avocado_data                         \u001b[32m✔ Passed\u001b[0m   7 of 7 (100.0 %)\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!great_expectations checkpoint run avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to summarize: a checkpoint is a _runnable check_ for your data. They are your first stop for integrating Great Expectations into your pipelines and workflows.\n",
    "For more info on how to do that, refer to the [validation guides](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/validation.html), or the [workflows and patterns](https://docs.greatexpectations.io/en/latest/guides/workflows_patterns.html) guides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we explored how we could get some metrics about our data using expectations. But what if you don't know what exactly to expect of your data? Well, you could try using Great Expectations' profiling feature, which can try to extract some useful metrics from your data. To try profiling our preconfigured `data_dir` data source, we can use the CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!great_expectations datasource profile data_dir -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running that command should have presented you with freshly built data docs. You can find the results in the `Profiling Results` tab. The profiler also generated an expectation suite based on its observations, which you can find in the `Expectation Suites` tab. Be mindful that this is an experimental feature and the generated suite is usually not that helpful, but it could be a good starting point for writing your own.\n",
    "\n",
    "\n",
    "If you'd like to know more about profiling, the [profiling reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/profiling_reference.html) can help you out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-cli\"></a>\n",
    "# The Great Expectations CLI\n",
    "\n",
    "For the purposes of this tutorial, we mostly interacted directly with Great Expectations. If you are going to set up and use Great Expectations for yourself, we recommend using the CLI as much as possible. The concepts should be familiar by now - refer to the  [CLI guide](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/miscellaneous/command_line.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: great_expectations [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  Welcome to the great_expectations CLI!\r\n",
      "\r\n",
      "  Most commands follow this format: great_expectations <NOUN> <VERB>\r\n",
      "\r\n",
      "  The nouns are: datasource, docs, project, suite, validation-operator\r\n",
      "\r\n",
      "  Most nouns accept the following verbs: new, list, edit\r\n",
      "\r\n",
      "  In particular, the CLI supports the following special commands:\r\n",
      "\r\n",
      "  - great_expectations init : create a new great_expectations project\r\n",
      "\r\n",
      "  - great_expectations datasource profile : profile a datasource\r\n",
      "\r\n",
      "  - great_expectations docs build : compile documentation from expectations\r\n",
      "\r\n",
      "Options:\r\n",
      "  --version      Show the version and exit.\r\n",
      "  -v, --verbose  Set great_expectations to use verbose output.\r\n",
      "  --help         Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  checkpoint           Checkpoint operations\r\n",
      "  datasource           Datasource operations\r\n",
      "  docs                 Data Docs operations\r\n",
      "  init                 Initialize a new Great Expectations project.\r\n",
      "  project              Project operations\r\n",
      "  store                Store operations\r\n",
      "  suite                Expectation Suite operations\r\n",
      "  validation-operator  Validation Operator operations\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!great_expectations --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps: setting up your own project\n",
    "\n",
    "To initialize your own project, run `great_expectations init` and follow the instructions. This will scaffold a simple configuration for you, just like the one we provided. \\\n",
    "Once you created your suite using `great_expectations suite new`, you can use the `great_expectations suite edit` command to open up an auto-generated notebook that you can use to set up your suite. You should be able to recognise the structure of the first part of this notebook a bit ;-)\n",
    "\n",
    "The [getting started guide](https://docs.greatexpectations.io/en/latest/guides/tutorials/getting_started.html) can  help you along the way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectations tutorial\n",
    "\n",
    "### What is Great Expectations?\n",
    "\n",
    "Great Expectations is a tool that allows you to test batch data. It generates reports about the data, containing documentation of the data translated from the definitions of the tests.\n",
    "\n",
    "### Why you should use it: data quality\n",
    "\n",
    "You should test your data for two main reasons:\n",
    "- better data quality leads to better predictions and insights relying on the data,\n",
    "- it's an additional way to test data pipelines.\n",
    "\n",
    "### Key concepts and terminology\n",
    "\n",
    "A *Datasource* is a source of data to be tested. For example, a SQL database.\n",
    "\n",
    "A *data asset* is a subset of data from a data source (that share the same structure). For example, a table in a SQL database.\n",
    "\n",
    "An *expectation* is the definition of a test on a data asset.\n",
    "\n",
    "An *expectation suite* is a set of expectations on a data asset.\n",
    "\n",
    "### Install and setup great_expectations\n",
    "\n",
    "To install Great Expectations, run `pip install great_expectations` in your terminal. Using a virtual environment is a good practice to install programs with `pip`.\n",
    "\n",
    "To initialize Great Expectations for a project, run `great_expectations init` in your terminal in the project's directory and follow the instructions.\n",
    "\n",
    "For more information on how to set up everything, have a look at https://docs.greatexpectations.io/en/latest/guides/tutorials/getting_started.html and feel free to refer to the official documentation.\n",
    "\n",
    "### How it works\n",
    "\n",
    "Great Expectations stores everything related to a project in the `great_expectations` subdirectory in the project's directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into it then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: explain what a context is\n",
    "\n",
    "By creating a new `DataContext` object, great_expectations will read the configuration we have already set up for you - don't worry about that for now, we'll get back to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data context ready, we can add an expectation suite. Think of this like a test suite, but for your data instead of for your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = context.create_expectation_suite(\n",
    "    \"check_avocado_data\",\n",
    "    overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our dataset, `avocado.csv`, from our data context. Again, don't worry about this too much, great_expectations usually handles this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kwargs = {\n",
    "    'datasource': 'data_dir',\n",
    "    'path': 'data/avocado.csv',\n",
    "}\n",
    "batch = context.get_batch(batch_kwargs, suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that's it for setup! Now let's have a look at the data we are working with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "\n",
       "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "\n",
       "   year  region  \n",
       "0  2015  Albany  \n",
       "1  2015  Albany  \n",
       "2  2015  Albany  \n",
       "3  2015  Albany  \n",
       "4  2015  Albany  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Some documentation that came with the data:\n",
    " - Date - The date of the observation\n",
    " - AveragePrice - the average price of a single avocado\n",
    " - type - agriculture type: conventional or organic\n",
    " - Region - the city or region of the observation\n",
    " - Total Volume - Total number of avocados sold\n",
    " - 4046 - Total number of avocados with PLU 4046 sold (small Hass)\n",
    " - 4225 - Total number of avocados with PLU 4225 sold (large Hass)\n",
    " - 4770 - Total number of avocados with PLU 4770 sold (extra large Hass)\n",
    " \n",
    "These descriptions sure help us to understand the dataset a bit better, but they don't exactly provide much guarantees. When consuming this dataset, what assumptions can we make? Will the `region` field always be specified? Will the `Date` field always be in the same format? Those sales counts, are they supposed to add up?\n",
    "\n",
    "great_expectations helps us to codify these properties by writing `Expectations`. Think of it like an unit test, but for data.\n",
    "\n",
    "We'll create a simple one to get started! Maybe we can just check whether a certain column is present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {},\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_to_exist('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great success! That column does indeed seem to exist.\n",
    "\n",
    "We received dict describing the result of the check. Since this was a very basic expectation, there is not that much in there, but keep an eye on the results as we proceed to more complicated expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's address one of the concerns we raised: can we add an `Expectation` that ensures every record will have its `region` specified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_not_be_null('region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! in the `result` section, we can now see that all 18249 records passed the check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add a check for the value type, so that we don't end up with numeric regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_of_type('region', 'str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do many different kinds of checks with great_expectations. For example, we can make sure all the listed avocado prices are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 11,\n",
       "    \"unexpected_percent\": 0.06027727546714888,\n",
       "    \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "    \"partial_unexpected_list\": [\n",
       "      0.49,\n",
       "      0.46,\n",
       "      3.03,\n",
       "      3.12,\n",
       "      3.25,\n",
       "      0.44,\n",
       "      0.49,\n",
       "      0.48,\n",
       "      3.05,\n",
       "      3.04,\n",
       "      3.17\n",
       "    ]\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! That failed. Looks like we have some outliers here!\n",
    "\n",
    "If we want to allow this, we can add some tolerance to the check by using the `mostly` parameter. Lets settle for having 99% of avocados being priced within the range we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 11,\n",
       "    \"unexpected_percent\": 0.06027727546714888,\n",
       "    \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "    \"partial_unexpected_list\": [\n",
       "      0.49,\n",
       "      0.46,\n",
       "      3.03,\n",
       "      3.12,\n",
       "      3.25,\n",
       "      0.44,\n",
       "      0.49,\n",
       "      0.48,\n",
       "      3.05,\n",
       "      3.04,\n",
       "      3.17\n",
       "    ]\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0, mostly=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using ordinal values, such as the `type` field in our dataset, we can easily check that only known values show up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"observed_value\": [\n",
       "      \"conventional\",\n",
       "      \"organic\"\n",
       "    ],\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.expect_column_distinct_values_to_be_in_set('type', ['conventional', 'organic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even add a check on the value frequencies! For example, if we want the ratio of organic to conventional to be roughly equal, we could check the [Kullback-Leiber divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between our assumed distribution, and the one that is observed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"observed_value\": 1.351245850704074e-08,\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {}\n",
       "}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_object = {\n",
    "    'values': ['conventional', 'organic'],\n",
    "    'weights': [0.5, 0.5],\n",
    "    \n",
    "}\n",
    "batch.expect_column_kl_divergence_to_be_less_than('type', partition_object, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we checked out some expectations, maybe try adding one yourself? You can check out the [glossary of expectations](https://docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html) for a complete list of what you can do. Go wild!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests == docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while we were experimenting up there, great_expectations remembered all the expectations we ran. Now we can easily inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-13T17:20:18+0100 - INFO - \t6 expectation(s) included in expectation_suite. Omitting 1 expectation(s) that failed when last run; set discard_failed_expectations=False to include them. result_format settings filtered.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.13.4\"\n",
       "  },\n",
       "  \"expectations\": [\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Date\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_to_exist\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"type\",\n",
       "        \"value_set\": [\n",
       "          \"conventional\",\n",
       "          \"organic\"\n",
       "        ]\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"region\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"AveragePrice\",\n",
       "        \"min_value\": 0.5,\n",
       "        \"max_value\": 3.0,\n",
       "        \"mostly\": 0.99\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"type\",\n",
       "        \"partition_object\": {\n",
       "          \"values\": [\n",
       "            \"conventional\",\n",
       "            \"organic\"\n",
       "          ],\n",
       "          \"weights\": [\n",
       "            0.5,\n",
       "            0.5\n",
       "          ]\n",
       "        },\n",
       "        \"threshold\": 0.1\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_kl_divergence_to_be_less_than\",\n",
       "      \"meta\": {}\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"region\",\n",
       "        \"type_\": \"str\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
       "      \"meta\": {}\n",
       "    }\n",
       "  ],\n",
       "  \"expectation_suite_name\": \"check_avocado_data\",\n",
       "  \"data_asset_type\": \"Dataset\"\n",
       "}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dict shows us how great_expectations keeps track of your expectation suite internally.\n",
    "\n",
    "This representation shows us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14T09:21:25+0100 - INFO - \t6 expectation(s) included in expectation_suite. Omitting 1 expectation(s) that failed when last run; set discard_failed_expectations=False to include them. result_format settings filtered.\n"
     ]
    }
   ],
   "source": [
    "batch.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the file structure of our great_expectations setup, and find out where our file went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mgreat_expectations\u001b[0m\r\n",
      "├── \u001b[01;34mcheckpoints\u001b[0m\r\n",
      "├── \u001b[01;34mexpectations\u001b[0m\r\n",
      "│   └── check_avocado_data.json\r\n",
      "├── great_expectations.yml\r\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\r\n",
      "│   ├── \u001b[01;34mpandas\u001b[0m\r\n",
      "│   │   └── validation_playground.ipynb\r\n",
      "│   ├── \u001b[01;34mspark\u001b[0m\r\n",
      "│   │   └── validation_playground.ipynb\r\n",
      "│   └── \u001b[01;34msql\u001b[0m\r\n",
      "│       └── validation_playground.ipynb\r\n",
      "└── \u001b[01;34mplugins\u001b[0m\r\n",
      "    └── \u001b[01;34mcustom_data_docs\u001b[0m\r\n",
      "        ├── \u001b[01;34mrenderers\u001b[0m\r\n",
      "        ├── \u001b[01;34mstyles\u001b[0m\r\n",
      "        │   └── data_docs_custom_styles.css\r\n",
      "        └── \u001b[01;34mviews\u001b[0m\r\n",
      "\r\n",
      "11 directories, 6 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree great_expectations -I \"uncommitted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's right there in the `expectations` folder! Remember that we named our suite `check_avocado_data` back at the start.\n",
    "\n",
    "If you don't trust us, feel free to check for yourself ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat great_expectations/expectations/check_avocado_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-13T17:20:47+0100 - INFO - Setting run_name to: 20210113T162047.180704Z\n",
      "2021-01-13T17:20:47+0100 - INFO - \t7 expectation(s) included in expectation_suite.\n"
     ]
    }
   ],
   "source": [
    "results = context.run_validation_operator(\"action_list_operator\", assets_to_validate=[batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: make sure these docs are in the repo, and linke to them for online readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result_identifier = results.list_validation_result_identifiers()[0]\n",
    "context.build_data_docs()\n",
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'ActionListValidationOperator',\n",
       "  'action_list': [{'name': 'store_validation_result',\n",
       "    'action': {'class_name': 'StoreValidationResultAction'}},\n",
       "   {'name': 'store_evaluation_params',\n",
       "    'action': {'class_name': 'StoreEvaluationParametersAction'}},\n",
       "   {'name': 'update_data_docs',\n",
       "    'action': {'class_name': 'UpdateDataDocsAction'}}],\n",
       "  'name': 'action_list_operator'}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.list_validation_operators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "## Profiling: generating expectations\n",
    "\n",
    "## Setting up data context and source\n",
    "\n",
    "## (Airflow integration)\n",
    "\n",
    "## (Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat great_expectations/great_expectations.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = ge.read_csv(\"data/avocado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"meta\": {},\n",
       "  \"result\": {\n",
       "    \"element_count\": 18249,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 9123,\n",
       "    \"unexpected_percent\": 49.991780371527206,\n",
       "    \"unexpected_percent_nonmissing\": 49.991780371527206,\n",
       "    \"partial_unexpected_list\": [\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\",\n",
       "      \"organic\"\n",
       "    ]\n",
       "  },\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head()\n",
    "my_df.expect_column_values_to_be_in_set(\"type\", [\"conventional\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.13.4\"\n",
       "  },\n",
       "  \"expectation_suite_name\": \"default\",\n",
       "  \"data_asset_type\": \"Dataset\",\n",
       "  \"expectations\": []\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.get_expectation_suite()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

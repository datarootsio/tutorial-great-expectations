{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectations tutorial\n",
    "\n",
    "TODO: update the following paragraph as the project evolves\n",
    "\n",
    "Welcome to this hands-on tutorial on Great Expectations! We'll show you why and how to use Great Expectations to enhance the quality of your data. We'll first introduce you to the tool and show you how to get started. Then we'll go over expectations and expectation suites, which are the key building blocks to test your data. We'll show you how to generate beautiful reports on your data. We'll then build a checkpoint, and finally introduce you to more advanced stuff.\n",
    "\n",
    "### What is Great Expectations exactly?\n",
    "\n",
    "Great Expectations is a tool that allows you to test batch data. It generates reports about the data, containing documentation of the data translated from the definitions of the tests.\n",
    "\n",
    "### Why you should use it: data quality\n",
    "\n",
    "You should test your data for two main reasons:\n",
    "- better data quality leads to better predictions and insights relying on the data,\n",
    "- it's an additional way to test data pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into it then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need a `DataContext`. This represents a Great Expectations project, holding all your configurations, expectation suites, data sources and so on. We'll go over how to configure a `DataContext` yourself later [TODO: jump-ahead], but to get started we shipped a simple one with this tutorial.\n",
    "\n",
    "We'll load that one right now. By default, Great Expectations will look for your configuration in the `great_expectations` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `DataContext` ready, we can add an expectation suite. Think of this like a test suite, but for your data instead of for your code. Usually you'll do this through the CLI, but we will get to that later [TODO: jump-ahead]. We'll name the suite `check_avocado_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = context.create_expectation_suite(\n",
    "    \"check_avocado_data\",\n",
    "    overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our dataset, `avocado.csv`, from our data context. This involves a bit of configuration, but don't worry about it too much for now. We'll get back to that later [TODO: when + link]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_kwargs = {\n",
    "      'path': 'data/avocado.csv',\n",
    "      'datasource': 'data_dir',\n",
    "      'reader_method': 'read_csv',\n",
    "      'data_asset_name': 'avocado',\n",
    "}\n",
    "batch = context.get_batch(batch_kwargs, suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that's it for setup!\n",
    "\n",
    "Let's continue to our avocado sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the documentation that came with the data:\n",
    " - Date - The date of the observation\n",
    " - AveragePrice - the average price of a single avocado\n",
    " - type - agriculture type: conventional or organic\n",
    " - Region - the city or region of the observation\n",
    " - Total Volume - Total number of avocados sold\n",
    " - 4046 - Total number of avocados with PLU 4046 sold (small Hass)\n",
    " - 4225 - Total number of avocados with PLU 4225 sold (large Hass)\n",
    " - 4770 - Total number of avocados with PLU 4770 sold (extra large Hass)\n",
    " \n",
    "These descriptions sure help us to understand the dataset a bit better, but they don't exactly provide much guarantees. When consuming this dataset, what assumptions can we make? Will the `region` field always be specified? Will the `Date` field always be in the same format? Those sales counts, are they supposed to add up?\n",
    "\n",
    "Great Expectations helps us to codify these properties in a set of `Expectations`. An `Expectation` is, well, something that you expect to be true in your data. Again, think of it like an unit test for your dataset.\n",
    "\n",
    "Let's run a basic `Expectation` to get started. For example, we could check whether the `Date` column is present in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_to_exist('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great success! That column does indeed seem to exist.\n",
    "\n",
    "The result `dict` we got back might seem a bit weird at first, but it will start to make sense as we move along the tutorial. Promise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple check that only assesses the data shape, but doesn't touch the values in there (it is a _table-level check_).\n",
    "\n",
    "Let's try adding a check for the values now. Maybe we can address one of the concerns we raised: can we add an `Expectation` that ensures every record will have its `region` specified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_not_be_null('region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! This time we got a bit more info back: the `result` section now contains some metrics about our data. We can see that all 18249 records passed the check, and there were no unexpected (i.e. `null`) values. If Great Expectations finds any offending values, they will be listed in the `partial_unexpected_list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do something that's a bit more strict. It would be nice, for example, to make sure that all `region`s are actually strings, so that we don't end up with numeric regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_be_of_type('region', 'str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that metrics on the amount of missing values were still collected. This way, we can disambiguate between missing values and incorrect values. In case you were wondering, the `unexpected_percent_nonmissing` refers to the percentage of present (non-null) values that did not meet our expectation (they were not a string). If other metrics are unclear to you, check out [this documentation page](https://docs.greatexpectations.io/en/latest/reference/core_concepts/expectations/result_format.html#behavior-for-summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we covered the basics, let's get to some fancier expectations. For example, we could make sure that all `Date`s are in the expected format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_match_strftime_format('Date', \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example: we can make sure all the listed avocado prices are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! That failed. Looks like we have some outliers here! Great Expectations helpfully collected them for us. By default, it will collect up to 20 examples of values that didn't meet the expectation (that's why it's called the _partial_ unexpected list).\n",
    "\n",
    "If we want to allow these outliers, we can add some tolerance to the check by using the `mostly` parameter. Let's settle for having 99% of avocados being priced within the range we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_be_between('AveragePrice', min_value=0.5, max_value=3.0, mostly=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common usecase would be when you only expect a certain set of values to show up in a column. This is the case for our `type` column, since we only know about `conventional` and `organic` grown avocados. Let's add a check for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_distinct_values_to_be_in_set('type', ['conventional', 'organic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even add a check on the value frequencies! For example, if we want the ratio of organic to conventional to be roughly equal, we could check the [Kullback-Leiber divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between our assumed distribution, and the one that is observed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_object = {\n",
    "    'values': ['conventional', 'organic'],\n",
    "    'weights': [0.5, 0.5],\n",
    "    \n",
    "}\n",
    "batch.expect_column_kl_divergence_to_be_less_than('type', partition_object, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we checked out some expectations, maybe try adding one yourself? You can check out the [glossary of expectations](https://docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html) for a complete list of what you can do. Go wild!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stage is all yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Expectation Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while we were experimenting up there, great_expectations remembered all the expectations we ran. We can now retrieve the suite contents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gave us the `dict` representation Great Expectations uses under the hood to keep track of our exepectation suite. Can you recognise some of the expectations we wrote?\n",
    "\n",
    "This representation can then be saved to a file, so that we can load it again at another time, without depending on the python code that produced it.\n",
    "\n",
    "Note that by default, expectations that failed on the `batch` we ran them against will be omitted. If you want to include them anyways, you could add the `discard_failed_expectations=False` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us get back to that configuration we mentioned earlier. As we said, it's just some files living in the `great_expectations` directory. This is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree great_expectations -I \"uncommitted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have the main `great_expectations.yml` configuration file, a folder with checkpoints, a folder with expectation suites, some playground notebooks, and a folder for plugins.\n",
    "\n",
    "As you can see, the `save_expectation_suite` command saved our `check_avocado_data` suite to the `expectations` folder! That's all there is to it, the expectation suite is just a file. It contains that same internal representation that we just retrieved. You can check if you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat great_expectations/expectations/check_avocado_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we added our expectation suite to our `DataContext`, we can try running the entire suite. This is done by applying a `ValidationOperator` to the suite and the dataset. `ValidationOperator`s for your project are defined in the `great_expectations.yml` file. We already provided a `ValidationOperator` called `action_list_operator` [TODO: this is the default name, should we change it?] which will run the expectation suite and record its results.\n",
    "\n",
    "If you'd like to know more you can check out the [validation operators and actions](https://docs.greatexpectations.io/en/latest/reference/core_concepts/validation_operators_and_actions.html) or [how to add a validation operator](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/validation/how_to_add_a_validation_operator.html) documentation pages, but for it's sufficent to understand that you can configure these operators yourself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = context.run_validation_operator(\"action_list_operator\", assets_to_validate=[batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't specify our expectation suite for that command, but remember that the `batch` dataset kept track of our suite for us, so it will know what to do.\n",
    "\n",
    "That produced a big datadump for us. Let's inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"validation_operator_config\": {\n",
       "    \"class_name\": \"ActionListValidationOperator\",\n",
       "    \"module_name\": \"great_expectations.validation_operators\",\n",
       "    \"name\": \"action_list_operator\",\n",
       "    \"kwargs\": {\n",
       "      \"action_list\": [\n",
       "        {\n",
       "          \"name\": \"store_validation_result\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"StoreValidationResultAction\"\n",
       "          }\n",
       "        },\n",
       "        {\n",
       "          \"name\": \"store_evaluation_params\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"StoreEvaluationParametersAction\"\n",
       "          }\n",
       "        },\n",
       "        {\n",
       "          \"name\": \"update_data_docs\",\n",
       "          \"action\": {\n",
       "            \"class_name\": \"UpdateDataDocsAction\"\n",
       "          }\n",
       "        }\n",
       "      ],\n",
       "      \"result_format\": {\n",
       "        \"result_format\": \"SUMMARY\",\n",
       "        \"partial_unexpected_count\": 20\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"run_id\": {\n",
       "    \"run_name\": \"20210115T165147.798358Z\",\n",
       "    \"run_time\": \"2021-01-15T16:51:47.798358+00:00\"\n",
       "  },\n",
       "  \"evaluation_parameters\": null,\n",
       "  \"run_results\": {\n",
       "    \"ValidationResultIdentifier::check_avocado_data/20210115T165147.798358Z/20210115T165147.798358Z/a52e8a35d5f03815b708c7306612dbde\": {\n",
       "      \"validation_result\": {\n",
       "        \"statistics\": {\n",
       "          \"evaluated_expectations\": 7,\n",
       "          \"successful_expectations\": 7,\n",
       "          \"unsuccessful_expectations\": 0,\n",
       "          \"success_percent\": 100.0\n",
       "        },\n",
       "        \"meta\": {\n",
       "          \"great_expectations_version\": \"0.13.4\",\n",
       "          \"expectation_suite_name\": \"check_avocado_data\",\n",
       "          \"run_id\": {\n",
       "            \"run_name\": \"20210115T165147.798358Z\",\n",
       "            \"run_time\": \"2021-01-15T16:51:47.798358+00:00\"\n",
       "          },\n",
       "          \"batch_kwargs\": {\n",
       "            \"path\": \"data/avocado.csv\",\n",
       "            \"datasource\": \"data_dir\",\n",
       "            \"reader_method\": \"read_csv\",\n",
       "            \"data_asset_name\": \"avocado\"\n",
       "          },\n",
       "          \"batch_markers\": {\n",
       "            \"ge_load_time\": \"20210115T165115.674083Z\",\n",
       "            \"pandas_data_fingerprint\": \"9bc954aa566eaa4274cb680b2006c672\"\n",
       "          },\n",
       "          \"batch_parameters\": null,\n",
       "          \"validation_time\": \"20210115T165147.798691Z\"\n",
       "        },\n",
       "        \"results\": [\n",
       "          {\n",
       "            \"result\": {},\n",
       "            \"expectation_config\": {\n",
       "              \"meta\": {},\n",
       "              \"expectation_type\": \"expect_column_to_exist\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"Date\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"success\": true\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"unexpected_percent_nonmissing\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"partial_unexpected_index_list\": [],\n",
       "              \"partial_unexpected_counts\": []\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"meta\": {},\n",
       "              \"expectation_type\": \"expect_column_values_to_match_strftime_format\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"Date\",\n",
       "                \"strftime_format\": \"%Y-%m-%d\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"success\": true\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"partial_unexpected_list\": []\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"meta\": {},\n",
       "              \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"region\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"success\": true\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 0,\n",
       "              \"unexpected_percent\": 0.0,\n",
       "              \"unexpected_percent_nonmissing\": 0.0,\n",
       "              \"partial_unexpected_list\": [],\n",
       "              \"partial_unexpected_index_list\": [],\n",
       "              \"partial_unexpected_counts\": []\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"meta\": {},\n",
       "              \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"region\",\n",
       "                \"type_\": \"str\",\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"success\": true\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": 0,\n",
       "              \"missing_percent\": 0.0,\n",
       "              \"unexpected_count\": 11,\n",
       "              \"unexpected_percent\": 0.06027727546714888,\n",
       "              \"unexpected_percent_nonmissing\": 0.06027727546714888,\n",
       "              \"partial_unexpected_list\": [\n",
       "                0.49,\n",
       "                0.46,\n",
       "                3.03,\n",
       "                3.12,\n",
       "                3.25,\n",
       "                0.44,\n",
       "                0.49,\n",
       "                0.48,\n",
       "                3.05,\n",
       "                3.04,\n",
       "                3.17\n",
       "              ],\n",
       "              \"partial_unexpected_index_list\": [\n",
       "                1716,\n",
       "                7412,\n",
       "                13037,\n",
       "                14124,\n",
       "                14125,\n",
       "                15261,\n",
       "                15262,\n",
       "                15473,\n",
       "                16055,\n",
       "                16720,\n",
       "                17428\n",
       "              ],\n",
       "              \"partial_unexpected_counts\": [\n",
       "                {\n",
       "                  \"value\": 0.49,\n",
       "                  \"count\": 2\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.44,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.46,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 0.48,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.03,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.04,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.05,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.12,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.17,\n",
       "                  \"count\": 1\n",
       "                },\n",
       "                {\n",
       "                  \"value\": 3.25,\n",
       "                  \"count\": 1\n",
       "                }\n",
       "              ]\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"meta\": {},\n",
       "              \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"AveragePrice\",\n",
       "                \"min_value\": 0.5,\n",
       "                \"max_value\": 3.0,\n",
       "                \"mostly\": 0.99,\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"success\": true\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"observed_value\": [\n",
       "                \"conventional\",\n",
       "                \"organic\"\n",
       "              ],\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": null,\n",
       "              \"missing_percent\": null,\n",
       "              \"details\": {\n",
       "                \"value_counts\": [\n",
       "                  {\n",
       "                    \"value\": \"conventional\",\n",
       "                    \"count\": 9126\n",
       "                  },\n",
       "                  {\n",
       "                    \"value\": \"organic\",\n",
       "                    \"count\": 9123\n",
       "                  }\n",
       "                ]\n",
       "              }\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"meta\": {},\n",
       "              \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"type\",\n",
       "                \"value_set\": [\n",
       "                  \"conventional\",\n",
       "                  \"organic\"\n",
       "                ],\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"success\": true\n",
       "          },\n",
       "          {\n",
       "            \"result\": {\n",
       "              \"observed_value\": 1.351245850704074e-08,\n",
       "              \"element_count\": 18249,\n",
       "              \"missing_count\": null,\n",
       "              \"missing_percent\": null,\n",
       "              \"details\": {\n",
       "                \"observed_partition\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5000821962847279,\n",
       "                    0.49991780371527206\n",
       "                  ]\n",
       "                },\n",
       "                \"expected_partition\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5,\n",
       "                    0.5\n",
       "                  ]\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"expectation_config\": {\n",
       "              \"meta\": {},\n",
       "              \"expectation_type\": \"expect_column_kl_divergence_to_be_less_than\",\n",
       "              \"kwargs\": {\n",
       "                \"column\": \"type\",\n",
       "                \"partition_object\": {\n",
       "                  \"values\": [\n",
       "                    \"conventional\",\n",
       "                    \"organic\"\n",
       "                  ],\n",
       "                  \"weights\": [\n",
       "                    0.5,\n",
       "                    0.5\n",
       "                  ]\n",
       "                },\n",
       "                \"threshold\": 0.1,\n",
       "                \"result_format\": {\n",
       "                  \"result_format\": \"SUMMARY\"\n",
       "                }\n",
       "              }\n",
       "            },\n",
       "            \"exception_info\": {\n",
       "              \"raised_exception\": false,\n",
       "              \"exception_message\": null,\n",
       "              \"exception_traceback\": null\n",
       "            },\n",
       "            \"meta\": {},\n",
       "            \"success\": true\n",
       "          }\n",
       "        ],\n",
       "        \"evaluation_parameters\": {},\n",
       "        \"success\": true\n",
       "      },\n",
       "      \"actions_results\": {\n",
       "        \"store_validation_result\": {\n",
       "          \"class\": \"StoreValidationResultAction\"\n",
       "        },\n",
       "        \"store_evaluation_params\": {\n",
       "          \"class\": \"StoreEvaluationParametersAction\"\n",
       "        },\n",
       "        \"update_data_docs\": {\n",
       "          \"local_site\": \"file:///home/ilion/src/tutorial-great_expectations/great_expectations/uncommitted/data_docs/local_site/validations/check_avocado_data/20210115T165147.798358Z/20210115T165147.798358Z/a52e8a35d5f03815b708c7306612dbde.html\",\n",
       "          \"class\": \"UpdateDataDocsAction\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"success\": true\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a *validation result*. Validation results are kept in the *validation store*, which by default is the `great_expectations/uncommitted/validations` directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mgreat_expectations/uncommitted/validations\u001b[0m\r\n",
      "└── \u001b[01;34mcheck_avocado_data\u001b[0m\r\n",
      "    └── \u001b[01;34m20210115T165147.798358Z\u001b[0m\r\n",
      "        └── \u001b[01;34m20210115T165147.798358Z\u001b[0m\r\n",
      "            └── a52e8a35d5f03815b708c7306612dbde.json\r\n",
      "\r\n",
      "3 directories, 1 file\r\n"
     ]
    }
   ],
   "source": [
    "!tree great_expectations/uncommitted/validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great Expectations also allows you to set other backends as a validation store, such as an S3 bucket or a SQL database. Check out [metadata stores](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/configuring_metadata_stores.html) if you would like to learn more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can render these results to a friendly report, called a data doc. These data docs will describe the expectations that the data should meet, as well as the metrics detailing how well the data meets the requirements. This is how Great Expectations combines testing with documenting. Running the code below will generate the data docs and open them in a new tab, make sure to have a look around. You'll see the code we ran above reflected in the different sections - it's pretty self-explanatory!\n",
    "\n",
    "TODO: make sure these docs are in the repo, and add a link to them for online readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.build_data_docs()\n",
    "\n",
    "# get the result identifier for our run\n",
    "validation_result_identifier = list(results[\"run_results\"].keys())[0]\n",
    "context.open_data_docs(validation_result_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we manually ran our expectation suite against our dataset. While that worked, there is a better way: checkpoints.\n",
    "\n",
    "A checkpoint couples expectation suites with datasets that they will be run on. \\\n",
    "In Great Expectations parlance, we call these datasets *data assets*. Data assets live within a *datasource*. \\\n",
    "A datasource could for example be an SQL database, and a data asset could be one of its tables. The datasource we had preconfigured is just a simple folder with the `avocado` csv file inside. We named it `data_dir`.\n",
    "\n",
    "The check is ran using a *validation operator*. For now, we are just using the default one generated by great_expectations, called `action_list_operator`. It runs the expectation suites and generates the data docs we previously saw. Don't worry about this one yet, just remember that it can be configured.\n",
    "\n",
    "We can create a checkpoint by adding a file in the `checkpoints` directory of our great_expectations configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing great_expectations/checkpoints/avocado_data.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile great_expectations/checkpoints/avocado_data.yml\n",
    "\n",
    "validation_operator_name: action_list_operator\n",
    "batches:\n",
    "  - batch_kwargs:\n",
    "      path: data/avocado.csv\n",
    "      datasource: data_dir\n",
    "      reader_method: read_csv\n",
    "      data_asset_name: avocado\n",
    "    expectation_suite_names:\n",
    "      - check_avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`batches` is a list of (data asset, expectation suites) pairs. `batch_kwargs` specifies how the data asset should be loaded, you might recognise the parameters from earlier! \\\n",
    "Note that it is possible to add multiple expectation suites to check one batch.\n",
    "\n",
    "The checkpoint can be executed by using the great_expectations cli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mHeads up! This feature is Experimental. It may change. Please give us your feedback!\u001b[0m\u001b[0m\n",
      "Validation succeeded!\u001b[0m\n",
      "\n",
      "Suite Name                                   Status     Expectations met\u001b[0m\n",
      "- check_avocado_data                         \u001b[32m✔ Passed\u001b[0m   7 of 7 (100.0 %)\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!great_expectations checkpoint run avocado_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to summarize: a checkpoint is a _runnable check_ for your data. They are your first stop for integrating Great Expectations into your pipelines and workflows.\n",
    "For more info on how to do that, refer to the [validation guides](https://docs.greatexpectations.io/en/latest/guides/how_to_guides/validation.html), or the [workflows and patterns](https://docs.greatexpectations.io/en/latest/guides/workflows_patterns.html) guides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we explored how we could get some metrics about our data using expectations. But what if you don't know what exactly to expect of your data? Well, you could try using Great Expectations' profiling feature, which can try to extract some useful metrics from your data. To try profiling our preconfigured `data_dir` data source, we can use the CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!great_expectations datasource profile data_dir -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running that command should have presented you with freshly built data docs. You can find the results in the `Profiling Results` tab. The profiler also generated an expectation suite based on its observations, which you can find in the `Expectation Suites` tab. Be mindful that this is an experimental feature and the generated suite is usually not that helpful, but it could be a good starting point for writing your own.\n",
    "\n",
    "\n",
    "If you'd like to know more about profiling, the [profiling reference](https://docs.greatexpectations.io/en/latest/reference/spare_parts/profiling_reference.html) can help you out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and setup great_expectations\n",
    "\n",
    "Here are a few guidelines if you want to setup everything yourself for your own projects.\n",
    "\n",
    "To install Great Expectations, run `pip install great_expectations` in your terminal. Using a virtual environment is a good practice to install programs with `pip`.\n",
    "\n",
    "To initialize Great Expectations for a project, run `great_expectations init` in your terminal in the project's directory and follow the instructions.\n",
    "\n",
    "For more information on how to set up everything, have a look at https://docs.greatexpectations.io/en/latest/guides/tutorials/getting_started.html and feel free to refer to the official documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
